<!DOCTYPE html>
<html>
<head>
<title>Data Science for Social Good fellowship - University of Chicago</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/bootstrap-responsive.min.css" rel="stylesheet">
<link href="/css/custom.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">
<link href="/css/flat-ui.css" rel="stylesheet">
<script src="/js/modernizr.js"></script>
</head>
<body>
<!-- Navbar -->
<div class="navbar navbar-inverse navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">
            <!-- The Logo -->
            <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target="#nav-collapse-03">
            </button>
            <a href="http://dssg.io" id="nav-logo" class="brand">
                <!-- <i class="fui-loop" style="vertical-align: bottom;"></i> -->
                Data Science for Social Good</a>
            <div class="nav-collapse collapse" id="nav-collapse-03">
                <ul class="nav">
                    <li>
                    <a href="http://dssg.io/people">
                        People
                    </a>
                    </li>
                    <li>
                    <a href="http://dssg.io/projects">
                        Projects
                    </a>
                    </li>
                    <li>
                    <a href="http://dssg.io/events">
                        Events
                    </a>
                    </li>
                    <li>
                    <a href="http://dssg.io/contact">
                        Get involved
                    </a>
                    </li>
                    <li>
                    <a href="http://dssg.io/blog">
                        Blog
                    </a>
                    </li>
                    <li>
                    <a href="http://dssg.io/media">
                        Media
                    </a>
                    </li>
                </ul> <!-- /nav -->
            </div>
        </div>
    </div>
</div>
<!-- Header -->

<div class="container">
    <div class="row">
        <div class="span1">
        </div>
        <div class="span10">
            <h2 class="page-title">
                Legislative Influence Detector (LID)
                <hr/>
            </h2>
                <p class="answer">
                Journalists, researchers, and concerned citizens would like to know who’s writing legislative bills, but trying to read those bills, let alone trace their source, is tedious and time consuming. This is especially true at the state and local levels, where arguably more important policy decisions are made every day.</p>

                <p>The Legislative Influence Detector (LID) helps watchdogs turn this mountain of data into digestable insights about the origin and diffusion of policy ideas, the effectiveness of various lobbying organizations, and the democratic nature of individual bills, all in near real time. LID uses more than 500,000 state bills (collected by the <a href="sunlightfoundation.com">Sunlight Foundation</a>) and 2,400 pieces of model legislation (collected by us, <a href="http://www.alecexposed.org/wiki/ALEC_Exposed">ALEC Exposed</a>, and other groups) for textual similarities and flags them for review. The user can then investigate the matches.</p>

                <p>The screenshot below shows an example. On the left-hand side is text from <a href="http://docs.legis.wisconsin.gov/2015/proposals/sb179">Wisconsin Senate Bill 179</a> (2015), which bans most abortions past the 19th week of pregnancy. On the right-hand side is SB 179's highest-ranked match, <a href="https://legiscan.com/LA/text/SB593/2012">Louisiana Senate Bill 593</a> (2012). The highlighting shows that these sections match almost perfectly. Where differences exist, they are usually numbers versus spelling (e.g. “16” versus “sixteen”) or section identifiers (e.g. “(b)” versus “(9)”).</p>

                <img src="/img/posts/sunlight-reuse.png" align="center">

                <p>

                    Other tools can help investigate the origins of legislative bills. Many journalists and researchers read bills manually. Others use Google. Humans read slowly, and Google returns lots of non-legislative results. Inspired by <a href="http://onlinelibrary.wiley.com/doi/10.1111/ajps.12175/abstract">Wilkerson, Smith, and Stramp (2015)</a> and <a href="http://projects.iq.harvard.edu/govposters/file/357876">Hertel-Fernandez and Kashin</a>, LID is faster, cheaper, and easier to use than existing tools. In short, LID helps watchdogs stretch their limited resources further.</p>




            <h4>How Does It Work?</h4>
                <p class="answer">LID works in two steps:
                    <ol>
                        <li>For each document (either a bill or a piece of model legislation), we find the most similar documents as measured by their <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/practical-scoring-function.html">Lucene scores</a>.</li>
                        <li>We then run a <a href="https://en.wikipedia.org/wiki/Smith-Waterman_algorithm">Smith-Waterman local-alignment algorithm</a> to compare the query and the 100 documents chosen in step 1.</li>
                    </ol>
                </p>

                <p>
                    We could run the local-alignment on all documents, but it would take a long time to finish (possibly thousands of years!) The first step is a fast way to limit the number of comparisons the local-alignment algorithm needs to make. 
                    <!-- You can find the code <a href="github.com/dssg/policy_diffusion">here</a>. -->
                </p>


            <h4>How Do I Use the Data?</h4>
                <p class="answer">
                We provide data in two formats: <a href="https://en.wikipedia.org/wiki/Comma-separated_values">comma-separated values</a> (CSV) and <a href="https://en.wikipedia.org/wiki/JSON">JavaScript Object Notation</a> (JSON). Spreadsheet programs such as Excel can read CSVs, but you need more specialized programs to read JSON files, such as <a href="https://stedolan.github.io/jq/">jq</a>. We dropped some fields in the CSV (e.g. the text of the query document), but the JSON files have all the data.</p> 

                <p>These files contain the results for comparisons across states and between lobbying groups and states. We have not yet run comparisons within states. Many states reintroduce nearly entire bills, sometimes automatically, which means the matches are strong and the algorithm is slow. We will run the algorithm on all the bills soon.</p>

                <p>Here are the fields:
                    <ol>
                        <li><u>query_document_id</u>: The bill ID for the search document. The first two characters reference the state, the next set of characters reference the session (e.g. 2015-2016), and the last set of characters identify the bill.</li>
                        <li><u>comparison_document_id</u>: The bill ID for the comparison document.</li>
                        <li><u>lucene_score</u>: <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/practical-scoring-function.html">Lucene scores</a> are a measure of the match we found in step 1. The better the match, the higher the number. We only use these scores as a rough way to limit the number of comparison documents for step 2.</li>
                        <li><u>score</u>: A measure of the match we found in step 2. The numbers are a little hard to interpret directly, but longer the text match, the higher the score. If you order the results from highest to lowest, you'll have the best results at the top and the worst results at the bottom. 

                        Whatever Smith-Waterman cutoff you use, know that you're making a tradeoff: The higher the cutoff, the fewer false positives (incorrectly flagged matches) and the more false negatives (missed matches) you will get. We have found a decent set of matches only using scores over 100, but if you're worried about missing other bills, you can check the matches with scores under 100 too.</li>
                        <li><u>query_document_start</u>: The starting position of the matched text in the query document.</li>
                        <li><u>query_document_end</u>: The ending position of the matched text in the query document.</li>
                        <li><u>comparison_document_start</u>: The starting position of the matched text in the comparison document.</li>
                        <li><u>comparison_document_end</u>: The ending position of the matched text in the comparison document.</li>
                        <li><u>query_document_text</u>: The matched text in the query document.</li>
                        <li><u>comparison_document_text</u>: The matched text in the comparison document.</li>
                    </ol>
                </p>

                <p>These results are not comprehensive. We will not find matches on bills that failed to make their way into Sunlight's database. We will not find model legislation that is not public. Lobbyists and legislators may avoid detection by rewriting bills. Although LID would not find these examples, it does make re-using text more difficult. LID helps establish a minimum number of matches.</p>


            <h4>Isn't This Just Plagiarism Detection?</h4>
                <p class="answer">
                LID shares similarities with the typical plagiarism detector, but it differs in significant ways. Most plagiarism detectors use a "<a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag of words</a>" approach, where two documents are compared based on the similarity of the words they use, not the word order. For example, bag of words may consider "I kicked the ball," "The ball I kicked," and even "kicked the I ball" the same. In contrast, LID considers word order important.</p>

                <p>Because most plagiarism detectors look at how documents compare overall, they can miss matches on subsets of text. Using local alignments helps us find sections and even sentences that match. Because bills rarely pass across lobbying organizations and states without significant changes to some of their sections, local alignment is better suited for the task.</p>


            <h4>Where Do I Download the Dataset?</h4>
                <p class="answer">
		          We have two datasets: bill-to-bill comparisons and model legislation-to-bill comparisons. The former shows how bills spread across legislatures, and the latter show how ideas spread across lobbying groups and legislatures:
		          <ul> 
                    <li>Bill-to-bill comparisons in CSV format (updated through <a href="https://s3-us-west-2.amazonaws.com/policy-origination/bill_to_bill_alignments.csv">May, 2015</a>)</li>
			         <li>Bill-to-bill comparisons in JSON format (updated through <a href="https://s3-us-west-2.amazonaws.com/policy-origination/bill_to_bill_alignments.json">May, 2015</a>)</li>
                     <li>Model legislation-to-bill comparisons in CSV format (updated through <a href="https://s3-us-west-2.amazonaws.com/policy-origination/model_legislation_alignments.csv">May, 2015</a>)</li>
			         <li>Model legislation-to-bill comparisons in JSON format (updated through <a href="https://s3-us-west-2.amazonaws.com/policy-origination/model_legislation_alignments.json">May, 2015</a>)</li>
		          </ul>
                </p>



            <h4>Who are we?</h4>
            <p class="answer">
            <img src="/img/posts/sunlight15-team.png">
            </p>
        </div>
        <div class="span1">
        </div>
    </div>
</div>
<div class="container">
    <div class="row">
        <hr/>
        <h1 class="headline">
            <img id="logo" src="img/logo.png">
            <p>The Eric & Wendy Schmidt</p>
            Data Science for Social Good
            <p>Summer Fellowship</p>
            <img id="logo" src="/img/partners/uofc-new.jpg">
        </h1>
        <hr/>
    </div>
</div>

</body>
</html>
